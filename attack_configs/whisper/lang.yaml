# General information
seed: 1002
__set_seed: !apply:torch.manual_seed [!ref <seed>]
root: !PLACEHOLDER
tokenizers_folder: !ref <root>/tokenizers

# Hyparameters below are dependant on the attack and model used 
# and should be changed at the user's discretion
# -------------------------------------------------------------
# Attack information
snr: 40
nb_iter: 100

lang_CV: en
lang_attack: es
targeted_for_language: true

attack_class: !name:lang_attack.WhisperLanguageAttack
  snr: !ref <snr>
  nb_iter: !ref <nb_iter>
  language: !ref <lang_attack>
  targeted_for_language: !ref <targeted_for_language>
  rel_eps_iter: 0.1

attack_name: lang
save_audio: True
load_audio: True

# Model information
model_label: tiny
model_name: !ref whisper-<model_label>
target_brain_class: !name:sb_whisper_binding.WhisperASR
target_brain_hparams_file: !ref model_configs/<model_label>.yaml
source_model_name: !ref <model_name>
source_brain_class: !ref <target_brain_class>
source_brain_hparams_file: !ref model_configs/<model_label>.yaml

# Tokenizer information (compatible with target and source)
tokenizer_name: multilingual
tokenizer_builder: !name:whisper.tokenizer.get_tokenizer

   # -------------------------------------------------------------

output_folder: !ref <root>/attacks/<attack_name>/<lang_CV>-<lang_attack>/<source_model_name>/<seed>
wer_file: !ref <output_folder>/wer.txt
save_folder: !ref <output_folder>
log: !ref <output_folder>/log.txt
save_audio_path: !ref <output_folder>/save

dataset_prepare_fct: !name:robust_speech.data.common_voice.prepare_common_voice
  language: !ref <lang_CV>
  accented_letters: true
dataio_prepare_fct: !name:robust_speech.data.dataio.dataio_prepare

# Data files
data_folder: !ref <root>/data/CommonVoice/<lang_CV> # e.g, /localscratch/LibriSpeech
csv_folder: !ref <data_folder>/csv # e.g, /localscratch/LibriSpeech
test_splits: ["test"]
skip_prep: True
ckpt_interval_minutes: 15 # save checkpoint every N min
data_csv_name: test
test_csv:
   - !ref <data_folder>/csv/<data_csv_name>.csv
batch_size: 1 # This works for 2x GPUs with 32GB
avoid_if_longer_than: 24.0
sorting: random


# Feature parameters
sample_rate: 16000
n_fft: 400
n_mels: 80

# Decoding parameters (only for text_pipeline)
blank_index: 0
bos_index: 1
eos_index: 2

test_dataloader_opts:
    batch_size: 1

logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <log>
    
