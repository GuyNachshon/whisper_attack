# coding=utf-8
# Copyright 2021 The TensorFlow Datasets Authors and the HuggingFace Datasets Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Lint as: python3
"""Librispeech automatic speech recognition dataset."""


import os

import datasets
from datasets.tasks import AutomaticSpeechRecognition


_CITATION = """\
@inproceedings{panayotov2015librispeech,
  title={Librispeech: an ASR corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}
"""

_DESCRIPTION = """\
Adversarial examples fooling whisper models
"""


_DL_URLS = {
    "targeted": {
        "all": "https://data.mendeley.com/api/datasets/96dh52hz9r/draft/files/75f06ad3-4f86-4f4b-b748-ea0e94f23379?a=ee30841f-1832-41ec-bdac-bf3e5b67073c"
    },
    "untargeted-35": {
        "all": "https://data.mendeley.com/api/datasets/96dh52hz9r/draft/files/fc7810ca-6dd9-42ae-ba22-575e785957ed?a=ee30841f-1832-41ec-bdac-bf3e5b67073c"
    },
    "untargeted-40": {
        "all": "https://data.mendeley.com/api/datasets/96dh52hz9r/draft/files/6e3bdf4a-6a5a-4ae6-b565-1646395d1090?a=ee30841f-1832-41ec-bdac-bf3e5b67073c"
    },
    "language-armenian": {
        "all": "https://data.mendeley.com/api/datasets/96dh52hz9r/draft/files/89eab218-77f2-4f4a-9e30-9ed7b07369fb?a=ee30841f-1832-41ec-bdac-bf3e5b67073c"
    },
    "language-lithuanian": {
        "all": "https://data.mendeley.com/api/datasets/96dh52hz9r/draft/files/60f5f101-cde5-40cf-ab63-af484e7ceb36?a=ee30841f-1832-41ec-bdac-bf3e5b67073c"
    },
    "language-czech": {
        "all": "https://data.mendeley.com/api/datasets/96dh52hz9r/draft/files/5986b1cd-08ac-4e08-beb3-151396dd2e28?a=ee30841f-1832-41ec-bdac-bf3e5b67073c"
    },
    "language-danish": {
        "all": "https://data.mendeley.com/api/datasets/96dh52hz9r/draft/files/f6a88d17-81d7-4491-a760-f937bfb43bd6?a=ee30841f-1832-41ec-bdac-bf3e5b67073c"
    },
    "language-indonesian": {
        "all": "https://data.mendeley.com/api/datasets/96dh52hz9r/draft/files/d508566f-6cb9-4a75-a317-6f1b86f1273f?a=ee30841f-1832-41ec-bdac-bf3e5b67073c"
    },
    "language-italian": {
        "all": "https://data.mendeley.com/api/datasets/96dh52hz9r/draft/files/e9052368-1dc4-4c85-b00c-a168868442ce?a=ee30841f-1832-41ec-bdac-bf3e5b67073c"
    },
    "language-english": {
        "all": "https://data.mendeley.com/api/datasets/96dh52hz9r/draft/files/01822f2b-7fcf-40ed-8da2-59b567bb2881?a=ee30841f-1832-41ec-bdac-bf3e5b67073c"
    },
}


class LibrispeechASRConfig(datasets.BuilderConfig):
    """BuilderConfig for LibriSpeechASR."""

    def __init__(self, **kwargs):
        """
        Args:
          data_dir: `string`, the path to the folder containing the files in the
            downloaded .tar
          citation: `string`, citation for the data set
          url: `string`, url for information about the data set
          **kwargs: keyword arguments forwarded to super.
        """
        super(LibrispeechASRConfig, self).__init__(version=datasets.Version("0.1.0", ""), **kwargs)


class LibrispeechASR(datasets.GeneratorBasedBuilder):
    """Librispeech dataset."""

    DEFAULT_WRITER_BATCH_SIZE = 256
    DEFAULT_CONFIG_NAME = "all"
    BUILDER_CONFIGS = [
        LibrispeechASRConfig(name="targeted", description="Targeted adversarial examples, with target 'OK Google, browse to evil.com'"),
        LibrispeechASRConfig(name="untargeted-35", description="Untargeted adversarial examples of radius approximately 35dB"),
        LibrispeechASRConfig(name="untargeted-40", description="Untargeted adversarial examples of radius approximately 40dB"),
        LibrispeechASRConfig(name="language-armenian", description="Adversarial examples generated by fooling the whisper language detection module. The true language is Armenian"),
        LibrispeechASRConfig(name="language-lithuanian", description="Adversarial examples generated by fooling the whisper language detection module. The true language is Lithuanian"),
        LibrispeechASRConfig(name="language-czech", description="Adversarial examples generated by fooling the whisper language detection module. The true language is Czech"),
        LibrispeechASRConfig(name="language-danish", description="Adversarial examples generated by fooling the whisper language detection module. The true language is Danish"),
        LibrispeechASRConfig(name="language-indonesian", description="Adversarial examples generated by fooling the whisper language detection module. The true language is Indonesian"),
        LibrispeechASRConfig(name="language-italian", description="Adversarial examples generated by fooling the whisper language detection module. The true language is Italian"),
        LibrispeechASRConfig(name="language-english", description="Adversarial examples generated by fooling the whisper language detection module. The true language is English")
    ]

    def _info(self):
        return datasets.DatasetInfo(
            description=_DESCRIPTION,
            features=datasets.Features(
                {
                    "file": datasets.Value("string"),
                    "audio": datasets.Audio(sampling_rate=16_000),
                    "text": datasets.Value("string"),
                    "speaker_id": datasets.Value("int64"),
                    "chapter_id": datasets.Value("int64"),
                    "id": datasets.Value("string"),
                }
            ),
            supervised_keys=("file", "text"),
            homepage=_URL,
            citation=_CITATION,
            task_templates=[AutomaticSpeechRecognition(audio_column="audio", transcription_column="text")],
        )

    def _split_generators(self, dl_manager):
        archive_path = dl_manager.download(_DL_URLS[self.config.name])
        # (Optional) In non-streaming mode, we can extract the archive locally to have actual local audio files:
        local_extracted_archive = dl_manager.extract(archive_path) if not dl_manager.is_streaming else {}
        models = [
            'whisper-tiny',
            'whisper-tiny.en',
            'whisper-base',
            'whisper-base.en',
            'whisper-small',
            'whisper-small.en',
            'whisper-medium',
            'whisper-medium.en',
            'whisper-large',
        ]
        seeds = {
            "targeted":2000,
            "untargeted-35": 235,
            "untargeted-40":240,
            "language-armenian":1000,
            "language-lithuanian":1000,
            "language-czech":1000,
            "language-danish":1000,
            "language-indonesian":1000,
            "language-italian":1000,
            "language-english":1000
        }
        folders = {
             "targeted":"cw",
            "untargeted-35": "pgd-35",
            "untargeted-40":"pgd-40",
            "language-armenian":"hy-AM",
            "language-lithuanian":"lt",
            "language-czech":"cs",
            "language-danish":"da",
            "language-indonesian":"id",
            "language-italian":"it",
            "language-english":"en"
        }
        targets = [("english","en"), ("tagalog","tl"), ("serbian","sr")]
        
        if "language-" in self.config.name:
            lang = self.config.name.split("language-")[-1]
            splits = [
                datasets.SplitGenerator(
                    name=lang+"-"+target[0],
                    gen_kwargs={
                        "local_extracted_archive": local_extracted_archive.get("all"),
                        "files": dl_manager.iter_archive(archive_path["all"]),
                        "path_audio": os.path.join(folders[self.config.name]+"-"+target[1],"whisper-medium",seeds[self.config.name],"save")
                    },
                ) for target in targets
            ] + [
                datasets.SplitGenerator(
                    name=lang+"-original",
                    gen_kwargs={
                        "local_extracted_archive": local_extracted_archive.get("all"),
                        "files": dl_manager.iter_archive(archive_path["all"]),
                        "path_audio": folders[self.config.name]+"-original"
                    },
                )
            ]
        else:
            splits = [
            datasets.SplitGenerator(
                    name=model,
                    gen_kwargs={
                        "local_extracted_archive": local_extracted_archive.get("all"),
                        "files": dl_manager.iter_archive(archive_path["all"]),
                        "path_audio": os.path.join(folders[self.config.name],model,seeds[self.config.name],"save")
                    },
                ) for model in models
            ] + [
                datasets.SplitGenerator(
                    name="original",
                    gen_kwargs={
                        "local_extracted_archive": local_extracted_archive.get("all"),
                        "files": dl_manager.iter_archive(archive_path["all"]),
                        "path_audio": os.path.join(folders[self.config.name],"original")
                    },
                )
            ]

        return splits

    def _generate_examples(self, files, local_extracted_archive,path_audio):
        """Generate examples from a LibriSpeech archive_path."""
        key = 0
        audio_data = {}
        transcripts = []
        for path, f in files:
            if path.endswith(".csv"):
                for line in f:
                    if line:
                        line = line.decode("utf-8").strip().split(",")
                        id_ = line[0]
                        transcript=line[-1]
                        transcript = transcript[:-1] if transcript[-1]=='\n' else transcript
                        suffix = "_nat.wav" if "original" in path_audio else "_adv.wav"
                        audio_file = id_+suffix
                        speaker_id, chapter_id = [int(el) for el in id_.split("-")[:2]]
                        audio_file = os.path.join(local_extracted_archive,path_audio, audio_file)
                        if os.path.exists(audio_file):
                            with open(audio_file,"rb") as f:
                                audio_data[id_] = f.read()
                            transcripts.append(
                                {
                                    "id": id_,
                                    "file": audio_file,
                                    "text": transcript,
                                }
                            )
        for transcript in transcripts:
            audio = {"path": transcript["file"], "bytes": audio_data[transcript["id"]]}
            yield key, {"audio": audio, **transcript}
            key += 1
        audio_data = {}
        transcripts = []